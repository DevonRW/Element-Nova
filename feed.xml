<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Blog Name</title>
  <subtitle>Blog subtitle</subtitle>
  <id>http://blog.url.com/</id>
  <link href="http://blog.url.com/"/>
  <link href="http://blog.url.com/feed.xml" rel="self"/>
  <updated>2014-03-22T00:00:00Z</updated>
  <author>
    <name>Blog Author</name>
  </author>
  <entry>
    <title>now on Middleman</title>
    <link rel="alternate" href="http://blog.url.com/2014/03/22/now-on-middleman.html"/>
    <id>http://blog.url.com/2014/03/22/now-on-middleman.html</id>
    <published>2014-03-22T00:00:00Z</published>
    <updated>2014-03-26T21:04:26-06:00</updated>
    <author>
      <name>Article Author</name>
    </author>
    <content type="html">&lt;p&gt;Moved the blogging system from Piecrust over to Middleman. It seems to do the job just fine.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Warlords of Draenor Performance Audit</title>
    <link rel="alternate" href="http://blog.url.com/2014/01/30/warlords-of-draenor-perf-audit.html"/>
    <id>http://blog.url.com/2014/01/30/warlords-of-draenor-perf-audit.html</id>
    <published>2014-01-30T00:00:00Z</published>
    <updated>2014-03-22T00:14:00-06:00</updated>
    <author>
      <name>Article Author</name>
    </author>
    <content type="html">&lt;h1 id="warlords-of-draenor-microsite-performance-audit"&gt;Warlords of Draenor Microsite Performance Audit&lt;/h1&gt;

&lt;p&gt;I noticed when I looked at the Warlods of Draenor microsite that it took quite awhile to load the page. After my initial investigation I found out that it had 96 assets on the pages (including the HMTL file itself), and was 5MB in size.&lt;/p&gt;

&lt;p&gt;To pinpoint some of the issues I had a look at 4 different performance tools. Chrome Devtools Network Tab, Google PageSpeed Browser Plugin, Google Devtools Audit, and Webpagetest.org.&lt;/p&gt;

&lt;p&gt;Along the way I'll be adding in what the Total requests would be and what the Total file size would be if what I had found were to be implemented. Keep in mind I haven't actually implemented it so the Total file size is based off data from the tools. For example, I mentioning combining images into an image sprite. If separately 4 images are 5KB I'm unsure if put into an image sprite that they'd be 20KB. So the Total file size will be based off the data, not actually results.&lt;/p&gt;

&lt;h2 id="network-tab-results"&gt;Network Tab Results&lt;/h2&gt;
&lt;p&gt;The network tab is where I found out that it has 96 requests. The total size sent is 5.0 MB. It took 38.66 seconds to send and display everything.&lt;/p&gt;

&lt;p&gt;The 96 requests was bothersome. It's generally pretty easy to get it down under 50 requests with little effort (Image Sprites and combining JS or CSS files). Web browsers can only handle so many requests at a time, so the fewer total requests, the faster everything displays. It feels like some of the files could be borrowed from a general "Blizzard" style or js library(s), however, using a build tool that combines them before deploying like Grunt, or using something like mod_pagespeed could take care of that if, for some reason, they're unable to to manually combine those files.&lt;/p&gt;

&lt;h2 id="google-pagespeed-browser-plugin-results"&gt;Google PageSpeed Browser Plugin Results&lt;/h2&gt;
&lt;p&gt;Running this pulled up only a few things. Of the 27 tests it runs it only found 9 things to improve on, so that's a plus.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Reduce blocking resources
Inline small JS.
http://us.battle.net/…/carousels.js?v37, http://us.battle.net/…/main.js?v37, http://us.battle.net/…/map.js?v37, http://us.battle.net/…/questing.js?v37 are all very small files, and could be inlined into the page itself to remove 4 requests. As well, since JS files block page rendering having fewer is rather ideal. If these could just be included into one or two "main" JS files then that'd be okay. Again, Grunt could accomplish something like that.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Total requests: 92
Total size: 5.0MB&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Minimize payload (reduce filesize and reduce requests)
    &lt;ol&gt;
      &lt;li&gt;Optimize images
 A lot of the images look to be optimized already, however, this tool did pull up that more could be done. 93KB could be removed from the total size. Not lots, but when you have 5.0MB to reduce, starting with removing 93KB is an okay start. If there's a way to automate image compression with a tool during development this would be ideal, so that it doesn't get missed.&lt;/li&gt;
    &lt;/ol&gt;

    &lt;p&gt;Total requests: 92
 Total size: 4.91MB&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;Combine images into CSS sprites.
 5 images are listed as being good candidates to combining into an image sprite. Doing so would reduce the number of requests by another 4 (because we're adding one for the sprite).&lt;/li&gt;
    &lt;/ol&gt;

    &lt;p&gt;Total requests: 88
 Total size: 4.91MB&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;Minify JavaScript
 Could reduce the total size by 19KB. Automate this in the build.&lt;/li&gt;
    &lt;/ol&gt;

    &lt;p&gt;Total requests: 88
 Total size: 4.72MB&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;Minify CSS
 I use Sass so this is automated for me, however there are other build tools that could be used. CSS is also typically not very beneficial to minify, however, if it's automated then it isn't an issue. Can reduce file size by 1.3KB (yea, see, very little gain)&lt;/li&gt;
    &lt;/ol&gt;

    &lt;p&gt;Total requests: 88
 Total size: 4.707MB&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;Minify HTML
 Typically overlooked, minifying HTML can crunch out a bit from the total size. In this case it's 930B (or 0.90KB)&lt;/li&gt;
    &lt;/ol&gt;

    &lt;p&gt;Total requests: 88
 Total size: 4.706KB&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Other
    &lt;ol&gt;
      &lt;li&gt;Leverage browser caching
 There's about 30 files set to expire after 1 day. It could be possible to setup the files to have a far future expiration date and still have them versioned or be replaced nicely. For example. Naming the file login.37.js instead of login.js with a query string at the end and then having the markup updated automatically to pull it in if updated to login.38.js would be ideal. Can be awkward to setup at first but there are several solutions out there to provide this.&lt;/li&gt;
      &lt;li&gt;Defer parsing of JavaScript
 According to this tool some JS is being grabbed before it's needed. Moving it lower into the code would speed how soon a user sees information.&lt;/li&gt;
      &lt;li&gt;Remove quest string from static resources
 Some proxy caching servers have problems with ? in the file name. The solution I mentioned under Leverage browser caching would take care of this.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id="google-devtools-audit-results"&gt;Google Devtools Audit Results&lt;/h2&gt;
&lt;p&gt;This pulled up some great information&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Combine external JavaScript (20 files)
Either manually put perferrably automate this. Being able to remove 19 requests with a small amount of wrok is a wonderful gain for performance.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Total requests: 69
Total size: 4.706KB&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Enable gzip compression (4)
It isn't being used on the .webm files. Could save 1.2MB&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Total requests: 69
Total size: 3.5MB&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Remove unused CSS rules (61%)
Likely a lot of these rules come from the fact that the CSS files are used across the site. I'm going to guess that removing 61% of the code from the file would reduce the filesize of the 59.8KB CSS files (total size), even though it isn't 100% accurate. So 39% of 59.8KB is 22.72KB (according to Google anyways)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Total requests: 69
Total size: 3.47MB&lt;/p&gt;

&lt;p&gt;I was surprised it didn't pull up more for image combining nor point out that there's 3 CSS files and that they could easily be 1. So, let's combine the 3 CSS files into 1. The real trick with web performance is to keep applying it during the initial creation of the site. Coming to it after the site is done often ends with fewer possible improvements.&lt;/p&gt;

&lt;p&gt;Total requests: 67
Total size: 3.47MB&lt;/p&gt;

&lt;h2 id="webpagetestorg-results"&gt;WebPageTest.org Results&lt;/h2&gt;
&lt;p&gt;The site did quite well on the test: http://www.webpagetest.org/result/140101_ER_3EP/1/performance_optimization/&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Compress Images: 81/100
This found that it was possible to get 434.4KB savings, as opposed to the 93KB that Google Page Speed said. So let's use the bigger number of savings. 3.47MB + 93KB - 434KB (I'm assuming that the two image compression results are not cumulative).&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Total requests: 67
Total size: 3.2MB&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Use Progressive JPEGs: 14/100
So far I've mainly only mentioned ways to reduce file size and number of assets that come acorss. Progressize JPEGs is something entirely different. Progressive JPEGs render differenly to the user. A poor quality image is displayed and then a higher quality image is displayed in layers several times over until the final version displays. Demo video: https://www.youtube.com/watch?v=TOc15-2apY0&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The images can sometimes be sligthly larger, however, they give the user something to see near instantly, whereas "non-interlaced" JPEGs do not display everything until the entire image as been downloaded.&lt;/p&gt;

&lt;p&gt;Progressive JPEGs can give the user something to see sooner, so that's the performance boost. I admit, I haven't tested them out too much.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Leverage browser caching of static assets: 65/100
WebPageTest pulled up that a lot of the images need better caching. This is consistent with what Google PageSpeed pulled up&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Use a CDN for all static assets: 15/100
Pretty much all Images, JS, and CSS files are listed. I was surprised that CSS files were listed, as if they're used on a CDN then you can end up with a pretty bad FOUT (flash of unstyled text) while it's loading it from a separate domain. CSS should ideally be on the same domain as the HTML file, to display a styled site as quickly as possible.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;CDNs are typically a great place to store your static assets for quick download. Easier to link to Wikipedia than try and explain it :) http://en.wikipedia.org/wiki/Content_delivery_network&lt;/p&gt;

&lt;h1 id="conclusion"&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;When looking at web page performance improvement after a site has been completed, typically the only thing that gets looked at is reducing file size and reducing requests. While these do provide a large improvement to overall page speed performance, these things should be looked at during the initial creation. By looking at performance earlier on in a project, it's easier to focus on improving JavaScript and CSS performance, which wasn't really discussed.&lt;/p&gt;

&lt;p&gt;I won't fault the developers for not completing some of these things that I've listed above. When we're working on a project we have priorities, and things end up changing on us, and we have deadlines, and so forth. Sometimes we, as developers, simply don't know about these things, or if we do, cannot make the time to complete them, or are unable to convince others that it's worth our time to complete.&lt;/p&gt;

&lt;p&gt;I don't know how much traffic http://us.battle.net/wow/en/warlords-of-draenor/ gets on a monthly basis. However, 1.8MB per user per visit being removed can have major improvements to a company's overall bandwidth charges. 10,000 visitors * 1.8MB = 17.6GB. And since this is Blizzard I'm assuming the number is much higher.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>BarCampYXE Recap</title>
    <link rel="alternate" href="http://blog.url.com/2013/05/28/barcampyxe-recap.html"/>
    <id>http://blog.url.com/2013/05/28/barcampyxe-recap.html</id>
    <published>2013-05-28T00:00:00Z</published>
    <updated>2014-03-22T00:14:00-06:00</updated>
    <author>
      <name>Article Author</name>
    </author>
    <content type="html">&lt;p&gt;I finally made it to a BarCamp. In fact, I actually spoke at it. More on that in a bit.&lt;/p&gt;

&lt;h2 id="what-i-learned-from-the-talks"&gt;What I learned from the talks&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;Coding live with people looks kinda stressful if something silly isn't working&lt;/li&gt;
  &lt;li&gt;Everyone's on your side&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id="what-i-learned-from-my-talk"&gt;What I learned from my talk&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;Have your presentation on your machine, since having internet access isn't gonna happen&lt;/li&gt;
  &lt;li&gt;Practicing a few times before hand sure helps when your notes aren't working for some dumb reason&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;All in all this was a good experience. I wasn't too happy with my presentation but I was happy that I did it.&lt;/p&gt;

&lt;p&gt;The talk I gave was mostly high level ideas about how we should build our websites for everyone by targeting HTML4 and then HTML5 browsers, as well as performance improving ideas. I'll be discussing these ideas in more details with the majority of the zu devs in the morning.&lt;/p&gt;

&lt;p&gt;Good catching up with &lt;a href="http://www.twitter.com/dmosher"&gt;@dmosher&lt;/a&gt;, &lt;a href="http://www.twitter.com/fexd"&gt;@fexd&lt;/a&gt;, &lt;a href="http://www.twitter.com/thebatlab"&gt;@thebatlab&lt;/a&gt; and finally meeting &lt;a href="http://www.twitter.com/interlock"&gt;@interlock&lt;/a&gt;, &lt;a href="http://www.twitter.com/gingerk"&gt;@gingerk&lt;/a&gt; in person.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Now on Piecrust</title>
    <link rel="alternate" href="http://blog.url.com/2013/04/02/now-on-piecrust.html"/>
    <id>http://blog.url.com/2013/04/02/now-on-piecrust.html</id>
    <published>2013-04-02T00:00:00Z</published>
    <updated>2014-03-22T00:13:59-06:00</updated>
    <author>
      <name>Article Author</name>
    </author>
    <content type="html">&lt;p&gt;I've moved this blog over onto Github pages as well as am now using &lt;a href="http://bolt80.com/piecrust/"&gt;Piecrust&lt;/a&gt; to generate the static pages.&lt;/p&gt;

&lt;p&gt;I haven't done anything special with piecrust, still just a basic install and have moved posts over. Took longer getting all this setup than I originally expected, however, git was being silly on my machine.&lt;/p&gt;

&lt;p&gt;I've removed all styles and js from the site for the time being. I'm thinking about slowly adding small things and seeing where things go. I may go with a mobile first adaptive design, or I may do nothing.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>RWD and Interactive Charts</title>
    <link rel="alternate" href="http://blog.url.com/2012/10/30/rwd-and-interactive-charts.html"/>
    <id>http://blog.url.com/2012/10/30/rwd-and-interactive-charts.html</id>
    <published>2012-10-30T00:00:00Z</published>
    <updated>2014-03-22T00:13:58-06:00</updated>
    <author>
      <name>Article Author</name>
    </author>
    <content type="html">&lt;p&gt;We've started a new project at work that involves implementing some interactive charts and will also be using RWD.&lt;/p&gt;

&lt;p&gt;Funny thing with Interactive Charts on smaller screens, if you are able to get the chart to take up the entire screen, you cannot swipe off it to continue scrolling.&lt;/p&gt;

&lt;p&gt;Heads up.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>PITDC Round 2</title>
    <link rel="alternate" href="http://blog.url.com/2012/10/03/pitdc-round-2.html"/>
    <id>http://blog.url.com/2012/10/03/pitdc-round-2.html</id>
    <published>2012-10-03T00:00:00Z</published>
    <updated>2014-03-22T00:13:58-06:00</updated>
    <author>
      <name>Article Author</name>
    </author>
    <content type="html">&lt;p&gt;I managed a better night's sleep compared to the night before, however it was harder to get up for some reason.&lt;/p&gt;

&lt;p&gt;I moseyed downstairs at about 1/2 way through breakfast time and noticed the Lean Coffee group was full. I also noticed my buddy, Andrew, was there. Andrew had supper with Ralph and myself last night and asked us tons of questions about Agile and processess and we gave as many tips as we could think of.
##Session 1: Multitaskers Anonymous
This session started with everyone standing up and doing an exercise to prove a point. This was led by Steve Rogalsky, same Agile dude from yesterday's Agile session. I really enjoyed yesterdays session and again, I enjoyed this session.&lt;/p&gt;

&lt;p&gt;The general idea behind this session was that interruptions cost money. Lots of money. And if you want to interrupt me because something is important, be aware that it'd better be MORE important than what I'm working on.&lt;/p&gt;

&lt;p&gt;We had a great Q/A session at the end. I spoke to Steve afterwards and thanked him for the sessions. He mentioned to me to read both "Getting things done" and "Personal Kanban". I found it interesting that Steve says "Kan Ban" not like everyone else I know says it "Can Ban". He says it "かんばん" … and if that doesn't come across in Hiragana it's "khan bahn". Anyways, I found that interesting and then realized that it's being said that way as it's a Japanese term/word/thinger.&lt;/p&gt;

&lt;p&gt;So yea, for 8am I sure learned a lot.&lt;/p&gt;

&lt;h2 id="session-2-open-data-thingermahoosit"&gt;Session 2: Open Data thingermahoosit&lt;/h2&gt;
&lt;p&gt;I don't remember the actual name of the session. Andy Dyck, Chad McCallum, and Dale Zack presented the overal ideas of Open Data, provided a few examples, and started a conversation. I was able to mention the map I put together using C.o.S's Open Data stuffs (&lt;a href="http://devonrw.github.com/2012SaskatoonElectionInteractiveMap/interactive-map.html"&gt;linky&lt;/a&gt;). I'm probably done working on it, onto other projects and learning.&lt;/p&gt;

&lt;h2 id="session-3-lets-get-organized"&gt;Session 3: Let's get Organized&lt;/h2&gt;
&lt;p&gt;This was presented by a guy from Point2, Chris Dagenais. He went through some more Agile ideas and while I've noticed no Agile peeps will come out and say it, Agile really seems to play on emotions. For this, if someone tells me to do something AND HOW TO DO IT, I'll do it and be pissed off. If someone presents me with a problem and needs my help, I'm emotionally invested and want to do well. I've noticed that whenever someone comes up to me with the solution and wants me to do it that I get frustrated that I'm doing it, when they have the solution. However, maybe a good way of working with that is simply pairing with them and letting them drive. They have the idea already and I can work with them to understand their idea fully, and they can be the ones to actually do it.&lt;/p&gt;

&lt;p&gt;Building a healthy culture was also discussed. The entire time this was discussed I couldn't stop thinking that I had emailed Eden saying that ladies who work at zu are showered in puppies and throw watermelons…just saying :D&lt;/p&gt;

&lt;p&gt;Chris used Voltron as an analogy for a team. I liked that. I'm using that. Thanks Chris!&lt;/p&gt;

&lt;p&gt;We had a decent group discussion after his presentation was over (I didn't realize he was done, I was touching notes onto my tablet and then this big discussion started).&lt;/p&gt;

&lt;p&gt;One thing that was discussed was removing people who were poor to the culture (toxic was the term used). Those of us with Agile experience said "fire em", which may sound harsh, but what are they actually costing your team/company's goals and revenue when you really dig down deep and look at numbers and smart sounding things. I mentioned that, at zu, we pair with developers after they make it past the 1st (or maybe 2nd) round of interviews. Pairing with a developer lets you know how well they work with the team. We had two teams want to hire the same woman because she worked so well with both of us. She was hired, sadly chose the other team, but luckily our teams have merged and now I'm working with her (boy I'm rambly…).&lt;/p&gt;

&lt;h2 id="lunch-pasta"&gt;Lunch: Pasta&lt;/h2&gt;
&lt;p&gt;Sat at a table with Ralph, Dave Mosher, Jordan, and… Dale Zak (I think). We had pasta, it was yummers.&lt;/p&gt;

&lt;p&gt;A game of jeopardy was played with 3 people and they all got Best Buy gift cards. None of them knew what Joss Whedon looked like.&lt;/p&gt;

&lt;h2 id="session-45-sencha-dojo"&gt;Session 4/5: Sencha Dojo!&lt;/h2&gt;
&lt;p&gt;Jordan Boesch gave a quick (45 minutes +) overview of Sencha and then we dug into the code and started building all the things.&lt;/p&gt;

&lt;p&gt;The code that was setup for us to download actually had a few bugs in it before it was useable. I'm not sure if Jordan did this on purpose or not. I learned a lot more by debugging the problems and having to think about what is going on as opposed to just typing what was on the screen, refreshing a page, and saying "yup, that happens here too". I've been to a couple Code Dojos over the past year and the idea of just typing what someone else types and getting the same result feels silly.&lt;/p&gt;

&lt;p&gt;It was kinda nice seeing that everyone seemed to run into a little snag while copy typing (that's what I'm calling it now, that's what it is :P) and they all were not the same. I ran into a couple problems with my code too, but it turns out that I naturall type PDF as opposed to PCD (I WONDER WHY?!? &lt;em&gt;sarcasm&lt;/em&gt;).&lt;/p&gt;

&lt;p&gt;Kevin and I had to head back to Saskatoon after our Senchaing was completed. I managed to make it home at about 7:20 and was able to have 2 sleeping girlies by 9pm. Turns out roughly 0% of the housework had been looked after. Nice. All caught up now.&lt;/p&gt;

&lt;h2 id="closing-thoughts"&gt;Closing Thoughts&lt;/h2&gt;
&lt;p&gt;A special thanks to zu for footing the bill for this trip/conference/mega-learn-a-thon. One thing I've been wanting to do for about a year now is go to a conference outside of Saskatoon. Being able to increase my abilities this way has been awesome.&lt;/p&gt;
</content>
  </entry>
</feed>
